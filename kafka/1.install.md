# 1, 搭建 Kafka 环境

本章的内容比较简单，我们将使用 Docker 快速部署一个单节点的 Kafka 或 Kafka 集群，在后面的章节中，将会使用已经部署好的 Kafka 实例做实验，然后我们通过不断地实验，逐渐了解 Kafka 的知识点以及掌握客户端的使用。 





这里笔者给出了单机和集群两种部署方式，但是为了便于学习后面的章节，请以集群的方式部署 Kafka。



### 安装 docker-compose

使用 docker-compose 部署 Kafka 可以减少很多没必要的麻烦，一个脚本即可完成部署，省下折腾时间。

安装 docker-compose 也是挺简单的，直接下载二进制可执行文件即可。



```bash
INSTALLPATH=/usr/local/bin
sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o ${INSTALLPATH}/docker-compose

sudo chmod +x ${INSTALLPATH}/docker-compose

docker-compose --version
```

> 如果系统没有映射 `/usr/local/bin/` 路径，执行命令完成后，如果发现找不到 `docker-compose` 命令，请将文件下载到 `/usr/bin`，即替换 `INSTALLPATH=/usr/local/bin` 为 `INSTALLPATH=/usr/bin`。



### 单节点 Kafka 的部署

创建一个 docker-compose.yml 文件，文件内容如下：



```yml
---
version: '3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-kafka:7.3.0
    container_name: broker
    ports:
    # To learn about configuring Kafka for access across networks see
    # https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.3.156:9092,PLAINTEXT_INTERNAL://broker:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    volumes:
      - /data/kafka/broker/logs:/opt/kafka/logs
      - /var/run/docker.sock:/var/run/docker.sock
```

> 请替换 `PLAINTEXT://192.168.3.156` 中的 IP 。



然后执行命令开始部署应用：

```bash
docker-compose up -d
```



接着，安装 kafdrop，这是一个 Kafka 管理界面，可以很方便地查看一些信息。

```bash
docker run -d --rm  -p 9000:9000 \
-e JVM_OPTS="-Xms32M -Xmx64M" \
-e KAFKA_BROKERCONNECT=192.168.3.156:9092 \
-e SERVER_SERVLET_CONTEXTPATH="/" \
obsidiandynamics/kafdrop
```

![image-20221217104808644](images/image-20221217104808644.png)



### Kafka 集群的部署

Kafka 集群的部署方法有很多，方法不尽相同，其中使用的配置参数（环境变量）也很多，这里笔者只给出自己在使用的快速部署参数，读者可以参阅官方文档，以便定制配置。



笔者的部署脚本中其中一些重要的环境变量说明如下：

* `KAFKA_BROKER_ID`: 当前 Broker 实例的 id，Broker id 不能重复；
* `KAFKA_NUM_PARTITIONS`：默认 Topic 的分区数量，默认为 1，如果设置了这个配置，自动创建的 Topic 会根据这个大小设置分区数量。
* `KAFKA_DEFAULT_REPLICATION_FACTOR`：默认 Topic 分区的副本数；
* `KAFKA_ZOOKEEPER_CONNECT`：Zookeeper 地址；
* `KAFKA_LISTENERS`：Kafka Broker 实例监听的 ip；
* `KAFKA_ADVERTISED_LISTENERS`：外部如何访问当前实例，用于 Zookeeper 监控；



创建一个 docker-compose.yml 文件，文件内容如下：

 ```yml
 ---
 version: '3'
 services:
   zookeeper:
     image: confluentinc/cp-zookeeper:7.3.0
     container_name: zookeeper
     environment:
       ZOOKEEPER_CLIENT_PORT: 2181
       ZOOKEEPER_TICK_TIME: 2000
 
   kafka1:
     image: confluentinc/cp-kafka:7.3.0
     container_name: broker1
     ports:
       - 19092:9092
     depends_on:
       - zookeeper
     environment:
       KAFKA_BROKER_ID: 1
       KAFKA_NUM_PARTITIONS: 3
       KAFKA_DEFAULT_REPLICATION_FACTOR: 2
       KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
       KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
       KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.3.158:19092
     volumes:
       - /data/kafka/broker1/logs:/opt/kafka/logs
       - /var/run/docker.sock:/var/run/docker.sock
       
   kafka2:
     image: confluentinc/cp-kafka:7.3.0
     container_name: broker2
     ports:
       - 29092:9092
     depends_on:
       - zookeeper
     environment:
       KAFKA_BROKER_ID: 2
       KAFKA_NUM_PARTITIONS: 3
       KAFKA_DEFAULT_REPLICATION_FACTOR: 2
       KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
       KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
       KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.3.158:29092
     volumes:
       - /data/kafka/broker2/logs:/opt/kafka/logs
       - /var/run/docker.sock:/var/run/docker.sock
       
   kafka3:
     image: confluentinc/cp-kafka:7.3.0
     container_name: broker3
     ports:
       - 39092:9092
     depends_on:
       - zookeeper
     environment:
       KAFKA_BROKER_ID: 3
       KAFKA_NUM_PARTITIONS: 3
       KAFKA_DEFAULT_REPLICATION_FACTOR: 2
       KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
       KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
       KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.3.158:39092
     volumes:
       - /data/kafka/broker3/logs:/opt/kafka/logs
       - /var/run/docker.sock:/var/run/docker.sock
 ```

> 由于三个 Broker 实例都在同一个虚拟机上面，因此这里通过暴露不同的端口，避免 Broker 冲突。



然后执行命令开始部署应用：

```bash
docker-compose up -d
```



接着部署 kafdrop：

```bash
docker run -d --rm  -p 9000:9000 \
-e JVM_OPTS="-Xms32M -Xmx64M" \
-e KAFKA_BROKERCONNECT=192.168.3.158:19092,192.168.3.158:29092,192.168.3.158:39092 \
-e SERVER_SERVLET_CONTEXTPATH="/" \
obsidiandynamics/kafdrop
```

![image-20221227202430307](images/image-20221227202430307.png)





现在，已经部署好了 Kafka 环境以及管理面板。